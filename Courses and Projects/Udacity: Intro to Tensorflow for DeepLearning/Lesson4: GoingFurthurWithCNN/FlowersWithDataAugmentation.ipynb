{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "l05c03_exercise_flowers_with_data_augmentation.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkqhwxTUlsXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" An Image classifier which classifies the images of flowers. To prevent Overfitting, we use the concept of Data Augmentation to increase \n",
        "the number of training examples. It is similar to Cats vs Dogs classifier except here we have more classes unlike in CatsVSDogs where we had\n",
        "only 2 classes \"\"\"\n",
        "\n",
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except:\n",
        "  pass\n",
        "\n",
        "# Imports \n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob \n",
        "import shutil # Helps to move the files\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2O1MPM6nzJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Downloading the dataset and creating a folder to hold it\n",
        "_URL = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "zip_file = tf.keras.utils.get_file(origin=_URL, extract=True, fname=\"flowers_photos.tgz\")\n",
        "base_dir = os.path.join(os.path.dirname(zip_file),\"flower_photos\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnR4_w3foRSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Labels\n",
        "classes = ['roses', 'daisy', 'dandelion', 'sunflowers', 'tulips']\n",
        "\n",
        "# Restructuring the dataset such that 80% images are in train folder and 20% in val folder\n",
        "for cl in classes:\n",
        "  img_path = os.path.join(base_dir,cl)\n",
        "  images = glob.glob(img_path + '/*.jpg')\n",
        "  train, val = images[:round(len(images)*0.8)], images[round(len(images)*0.8):]\n",
        "  print(\"{} : {} Images\".format(cl,len(images)))\n",
        "  for t in train:\n",
        "    if not os.path.exists(os.path.join(base_dir,\"train\",cl)):\n",
        "      os.makedirs(os.path.join(base_dir,\"train\",cl))\n",
        "    shutil.move(t,os.path.join(base_dir,\"train\",cl))\n",
        "\n",
        "  for v in val:\n",
        "    if not os.path.exists(os.path.join(base_dir,\"val\",cl)):\n",
        "      os.makedirs(os.path.join(base_dir,\"val\",cl))\n",
        "    shutil.move(v,os.path.join(base_dir,\"val\",cl))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBrsorPKsgFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(base_dir,'train')\n",
        "val_dir = os.path.join(base_dir,'val')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCMWHN8dtkQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 100\n",
        "image_size = 150"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS7lJxFLt8Ws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_images(images_arr):\n",
        "  image, axes = plt.subplots(1,5,figsize=(20,20)) # axes is a np array which contain position where we want to plot\n",
        "  axes = axes.flatten()\n",
        "  for img,ax in zip(images_arr,axes):\n",
        "    ax.imshow(img)\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "image_gen = ImageDataGenerator(rescale=1./255,\n",
        "                               rotation_range=45,\n",
        "                               zoom_range=0.5,\n",
        "                               horizontal_flip=True,\n",
        "                               width_shift_range=0.15,\n",
        "                               height_shift_range=0.15)\n",
        "\n",
        "train_data_gen = image_gen.flow_from_directory(train_dir,\n",
        "                                         batch_size = batch_size,\n",
        "                                         target_size = (image_size,image_size),\n",
        "                                         shuffle=True,\n",
        "                                         class_mode='sparse')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOCcaK5MwuBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aug_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plot_images(aug_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmubETT8xBEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen_val = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "val_data_gen = image_gen_val.flow_from_directory(val_dir,\n",
        "                             batch_size = batch_size,\n",
        "                             target_size = (image_size,image_size),\n",
        "                             class_mode='sparse')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkXr9bFkyyyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Conv2D(16,3,activation='relu'),\n",
        "                             tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "                             tf.keras.layers.Conv2D(32,3,activation='relu'),\n",
        "                             tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "                             tf.keras.layers.Conv2D(64,3,activation='relu'),\n",
        "                             tf.keras.layers.MaxPooling2D(2,2),\n",
        "                             \n",
        "                             tf.keras.layers.Dropout(0.2),\n",
        "                             tf.keras.layers.Flatten(),\n",
        "                             tf.keras.layers.Dense(512, activation='relu'),\n",
        "                             tf.keras.layers.Dense(5,activation='softmax')\n",
        "])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFsXbh9_1nBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LAFfaxl2DT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs=10\n",
        "history = model.fit(train_data_gen,\n",
        "                              validation_data=val_data_gen,\n",
        "                              epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HIm9ATs2XJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs_range,acc,label=\"Training Accuracy\")\n",
        "plt.plot(epochs_range,val_acc,label=\"Validation Accuracy\")\n",
        "plt.legend(loc='lower right')\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs_range,loss,label=\"Training Loss\")\n",
        "plt.plot(epochs_range,val_loss,label=\"Validation Loss\")\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "# Validation acc turned out to be more than Training Accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}