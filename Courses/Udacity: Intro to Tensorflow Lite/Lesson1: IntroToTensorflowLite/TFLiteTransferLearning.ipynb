{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" A Mobile Net model is imported from TFHub and it is used for predictions for cats_vs_dogs dataset. Finally, \n",
    "it will be saved as TFLite model after Optimizations and Interpretations. \"\"\"\n",
    "\n",
    "# Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4 with input size (224, 224) and output dimension 1280\n"
     ]
    }
   ],
   "source": [
    "# Getting model from TFHub. Inception model can also be used instead of MobileNet.\n",
    "\n",
    "module_selection = (\"mobilenet_v2\", 224, 1280) #@param [\"(\\\"mobilenet_v2\\\", 224, 1280)\", \"(\\\"inception_v3\\\", 299, 2048)\"] {type:\"raw\", allow-input: true}\n",
    "handle_base, pixels, FV_SIZE = module_selection\n",
    "MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(handle_base)\n",
    "IMAGE_SIZE = (pixels, pixels)\n",
    "print(\"Using {} with input size {} and output dimension {}\".format(\n",
    "  MODULE_HANDLE, IMAGE_SIZE, FV_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer_2 (KerasLayer)   (None, 1280)              2257984   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 2562      \n",
      "=================================================================\n",
      "Total params: 2,260,546\n",
      "Trainable params: 2,562\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building model and data\n",
    "splits = tfds.Split.ALL.subsplit(weighted=(80,10,10))\n",
    "splits, info = tfds.load(\"cats_vs_dogs\", with_info = True, as_supervised = True, split=splits)\n",
    "(train_examples, validation_examples, test_examples) = splits\n",
    "\n",
    "num_examples = info.splits['train'].num_examples\n",
    "num_classes = info.features['label'].num_classes\n",
    "\n",
    "def format_image(image, label):\n",
    "    image = tf.image.resize(image,IMAGE_SIZE) / 255.0\n",
    "    return image, label\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_batches = train_examples.shuffle(num_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
    "validation_batches = validation_examples.map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
    "test_batches = test_examples.map(format_image).batch(1)\n",
    "\n",
    "feature_extractor = hub.KerasLayer(MODULE_HANDLE, input_shape = IMAGE_SIZE + (3,), output_shape = [FV_SIZE],\n",
    "                                  trainable = False)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    feature_extractor,\n",
    "    tf.keras.layers.Dense(units=num_classes, activation='softmax')\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training(Not done here)\n",
    "EPOCHS=5\n",
    "history = model.fit(train_batches, validation_data=validation_batches, epochs=EPOCHS)\n",
    "\n",
    "# Exporting model\n",
    "CATS_VS_DOGS_SAVED_MODEL = 'exp_saved_model'\n",
    "tf.saved_model().save(model,CATS_VS_DOGS_SAVED_MODEL)\n",
    "\n",
    "loaded = tf.saved_model.load(CATS_VS_DOGS_SAVED_MODEL)\n",
    "print(list(loaded.signatures.keys()))\n",
    "infer = loaded.signatures[\"serving_default\"]\n",
    "print(infer.structured_input_signatures)\n",
    "print(infer.structured_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter\n",
    "converter = tf.lite.TFLiteConverter(CATS_VS_DOGS_SAVED_MODEL)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Representative Data Generator\n",
    "def representative_data_gen():\n",
    "    for input_value, _ in test_batches.take(100):\n",
    "        yield [input_value]\n",
    "        \n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "converter.target_specs.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "# Converted Model\n",
    "tflite_model = converter.convert()\n",
    "tflite_model_file = 'converted_model.tflite'\n",
    "\n",
    "with open(tflite_model_file,'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpreting data\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_model_file)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()[0]['index']\n",
    "output_details = interpreter.get_output_details()[0]['index']\n",
    "\n",
    "from tqdm import tqdm\n",
    "predictions = []\n",
    "test_labels, test_imgs = [], []\n",
    "for img,label in tqdm(test_batches.take(10)):\n",
    "    interpreter.set_tensor(input_details, img)\n",
    "    interpreter.invoke()\n",
    "    predictions.append(interpreter.get_tensor(output_details))\n",
    "    \n",
    "    test_labels.append(label.numpy()[0])\n",
    "    test_imgs.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing outputs and downloading it with tfLite model\n",
    "labels = ['cat','dog']\n",
    "with open('labels.txt','w') as f:\n",
    "    f.write('\\n'.join(labels))\n",
    "\n",
    "from google.colab import files\n",
    "files.download('converted_model.tflite')\n",
    "files.download('labels.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
